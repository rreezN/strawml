{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import deque\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weight_list(length, decay_factor=1.5):\n",
    "    \"\"\"\n",
    "    Create a weight list of specified length where:\n",
    "    - The first entry has the highest weight.\n",
    "    - Remaining weights decrease based on the decay factor.\n",
    "    - The total sum equals 1.\n",
    "\n",
    "    Args:\n",
    "        length (int): Length of the weight list.\n",
    "        decay_factor (float): Controls the rate of decrease. Higher values make weights drop faster.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of weights summing to 1.\n",
    "    \"\"\"\n",
    "    if length == 0:\n",
    "        return []\n",
    "    \n",
    "    # Generate decreasing weights\n",
    "    weights = [1 / (decay_factor ** i) for i in range(length)]\n",
    "    \n",
    "    # Normalize to ensure the sum is exactly 1\n",
    "    total_weight = sum(weights)\n",
    "    normalized_weights = [w / total_weight for w in weights]\n",
    "    return normalized_weights\n",
    "\n",
    "def _smooth(level, history, time_stamp = None, smooth_seconds=1):\n",
    "    # Get the current timestamp\n",
    "    if time_stamp is not None:\n",
    "        try: \n",
    "            current_time = float(time_stamp)\n",
    "        except:\n",
    "            current_time = time.time()\n",
    "    else:\n",
    "        current_time = time.time()\n",
    "\n",
    "    # Add the new prediction with its timestamp\n",
    "    history.append((current_time, level))\n",
    "\n",
    "    # Remove entries older than 1 second\n",
    "    while history and history[0][0] < current_time - smooth_seconds:\n",
    "        history.popleft()\n",
    "\n",
    "    # Compute the weighted average of the remaining predictions\n",
    "    if history:\n",
    "        predictions = [pred for _, pred in history]\n",
    "        weights = create_weight_list(len(predictions))\n",
    "        filtered_p_w = [(pi, wi) for pi, wi in zip(predictions, weights) if pi is not None]\n",
    "        predictions, weights = zip(*filtered_p_w)\n",
    "        avg_prediction = np.convolve(predictions, weights[::-1], mode='valid')\n",
    "    else:\n",
    "        avg_prediction = 0  # Default if no predictions are in the window\n",
    "    \n",
    "    return history, avg_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25139/25139 [00:11<00:00, 2195.52it/s]\n"
     ]
    }
   ],
   "source": [
    "yolo_smoothing_queue = deque()\n",
    "convnext_smoothing_queue = deque()\n",
    "\n",
    "typoo = 'rotated'\n",
    "smooth_seconds = 1\n",
    "clip_val = 2.5\n",
    "# load data from file\n",
    "file_path = f'../../data/predictions/new_run/recording_{typoo}_all_frames_processed.hdf5'\n",
    "\n",
    "yolo_smooth_dict = {}\n",
    "convnext_smooth_dict = {}\n",
    "yolo_clipped_dict = {}\n",
    "convnext_clipped_dict = {}\n",
    "\n",
    "with h5py.File(file_path, 'r') as hf:\n",
    "    timestamps = list(hf.keys())\n",
    "\n",
    "    if \"frame\" == timestamps[0].split(\"_\")[0]:\n",
    "        timestamps = sorted(timestamps, key=lambda x: int(x.split('_')[1]))\n",
    "    else:\n",
    "        timestamps = sorted(timestamps, key=lambda x: float(x))\n",
    "\n",
    "    prev_timestamp = None\n",
    "\n",
    "    for timestamp in tqdm(timestamps):\n",
    "        yolo_prediction = hf[timestamp]['yolo']['percent'][...]\n",
    "        convnext_prediction = hf[timestamp]['convnext']['percent'][...]\n",
    "        yolo_smoothing_queue, smoothed_yolo = _smooth(yolo_prediction, yolo_smoothing_queue, timestamp, smooth_seconds)\n",
    "        convnext_smoothing_queue, smoothed_convnext = _smooth(convnext_prediction, convnext_smoothing_queue, timestamp, smooth_seconds)\n",
    "\n",
    "        yolo_smooth_dict[timestamp] = smoothed_yolo\n",
    "        convnext_smooth_dict[timestamp] = smoothed_convnext\n",
    "\n",
    "        # run a clipping of yolo and convnext that states no more than 10% difference between each frame\n",
    "        if prev_timestamp is not None:\n",
    "            yolo_clipped = np.clip(yolo_prediction, a_min=yolo_clipped_dict[prev_timestamp] - clip_val, a_max=yolo_clipped_dict[prev_timestamp] + clip_val)\n",
    "            convnext_clipped = np.clip(convnext_prediction, a_min=convnext_clipped_dict[prev_timestamp] - clip_val, a_max=convnext_clipped_dict[prev_timestamp] + clip_val)\n",
    "        else:\n",
    "            yolo_clipped = yolo_prediction\n",
    "            convnext_clipped = convnext_prediction\n",
    "        \n",
    "        yolo_clipped_dict[timestamp] = yolo_clipped\n",
    "        convnext_clipped_dict[timestamp] = convnext_clipped\n",
    "        \n",
    "        prev_timestamp = timestamp\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 733/733 [00:00<00:00, 1337.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# Now we open the smaller files and write the smoothed predictions\n",
    "data_path = f'../../data/predictions/new_run/recording_{typoo}_all_frames_processed_combined.hdf5'\n",
    "with h5py.File(data_path, 'r+') as hf:\n",
    "    timestamps = list(hf.keys())\n",
    "    if \"frame\" == timestamps[0].split(\"_\")[0]:\n",
    "        timestamps = sorted(timestamps, key=lambda x: int(x.split('_')[1]))\n",
    "    else:\n",
    "        timestamps = sorted(timestamps, key=lambda x: float(x))\n",
    "        \n",
    "    for timestamp in tqdm(timestamps):\n",
    "        # define the group for the timestamp\n",
    "        group = hf[timestamp]\n",
    "        if f'yolo_smooth_{smooth_seconds}' in group:\n",
    "            del group[f'yolo_smooth_{smooth_seconds}']\n",
    "        # create the group for the smoothed predictions\n",
    "        yolo_smooth_group = group.create_group(f'yolo_smooth_{smooth_seconds}')\n",
    "        # write the smoothed predictions\n",
    "        yolo_smooth_group.create_dataset('percent', data=yolo_smooth_dict[timestamp])\n",
    "        \n",
    "        if f'convnext_smooth_{smooth_seconds}' in group:\n",
    "            del group[f'convnext_smooth_{smooth_seconds}']\n",
    "        # create the group for the smoothed predictions\n",
    "        convnext_smooth_group = group.create_group(f'convnext_smooth_{smooth_seconds}')\n",
    "        # write the smoothed predictions\n",
    "        convnext_smooth_group.create_dataset('percent', data=convnext_smooth_dict[timestamp])\n",
    "\n",
    "        if f'yolo_clipped_{clip_val}' in group:\n",
    "            del group[f'yolo_clipped_{clip_val}']\n",
    "        # create the group for the clipped predictions\n",
    "        yolo_clipped_group = group.create_group(f'yolo_clipped_{clip_val}')\n",
    "        # write the clipped predictions\n",
    "        yolo_clipped_group.create_dataset('percent', data=yolo_clipped_dict[timestamp])\n",
    "\n",
    "        if f'convnext_clipped_{clip_val}' in group:\n",
    "            del group[f'convnext_clipped_{clip_val}']\n",
    "        # create the group for the clipped predictions\n",
    "        convnext_clipped_group = group.create_group(f'convnext_clipped_{clip_val}')\n",
    "        # write the clipped predictions\n",
    "        convnext_clipped_group.create_dataset('percent', data=convnext_clipped_dict[timestamp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "strawenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
